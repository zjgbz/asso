{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import feather\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error \n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"/proj/yunligrp/users/minzhi/custom_lib\" not in sys.path:\n",
    "    sys.path.insert(0, \"/proj/yunligrp/users/minzhi/custom_lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function_process_data_eqtl import *\n",
    "from function_asso import *\n",
    "from function_mesa_cca import *\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_splitter(anno, df, cat_col, anno_merge_col_list, df_merge_col_list, all_cohorts, save_filename_prefix, save_dir_root, save_dir_base):\n",
    "    if anno.equals(df):\n",
    "        anno_df = copy.copy(anno)\n",
    "    else:\n",
    "        anno_df = anno.merge(df, left_on = anno_merge_col_list, right_on = df_merge_col_list, how = \"inner\")\n",
    "    _, cohort_list = categorize_df(anno_df, cat_col)\n",
    "    if all_cohorts == True:\n",
    "        cohort_list.append(\"all_cohorts\")\n",
    "    \n",
    "    for cohort in cohort_list:\n",
    "        if cohort == \"all_cohorts\":\n",
    "            df_cohort_raw = copy.copy(anno_df)\n",
    "        else:\n",
    "            df_cohort_raw = anno_df.loc[anno_df.loc[:, cat_col] == cohort, :]\n",
    "        df_id = df_cohort_raw[df_merge_col_list]\n",
    "        df_cohort = df.merge(df_id, on = df_merge_col_list, how = \"inner\")\n",
    "        df_cohort_filename = \"%s_%s.tsv\"%(save_filename_prefix, cohort)\n",
    "        save_dir = os.path.join(save_dir_root, cohort, save_dir_base)\n",
    "        df_cohort_dir_filename = os.path.join(save_dir, df_cohort_filename)\n",
    "        if not os.path.isdir(save_dir):\n",
    "            os.makedirs(save_dir, exist_ok = True)\n",
    "        df_cohort.to_csv(df_cohort_dir_filename, sep = \"\\t\", header = True, index = False)\n",
    "    return cohort_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kinship_simple(load_dir, filename_prefix):\n",
    "    load_dir_filename_prefix = os.path.join(load_dir, filename_prefix)\n",
    "    load_dir_filename_tsv = \"%s.tsv\"%load_dir_filename_prefix\n",
    "    load_dir_filename_feather = \"%s.feather\"%load_dir_filename_prefix\n",
    "    if os.path.exists(load_dir_filename_tsv):\n",
    "        kinship = pd.read_csv(load_dir_filename_tsv, sep = \"\\t\", header = 0, index_col = None)\n",
    "    elif os.path.exists(load_dir_filename_feather):\n",
    "        kinship = pd.read_feather(load_dir_filename_feather, use_threads = True)\n",
    "    return kinship\n",
    "\n",
    "def save_kinship_simple(save_dir, filename_prefix, kinship, sample_col = True):\n",
    "    save_dir_filename_prefix = os.path.join(save_dir, filename_prefix)\n",
    "    save_dir_filename_tsv = \"%s.tsv\"%save_dir_filename_prefix\n",
    "    save_dir_filename_feather = \"%s.feather\"%save_dir_filename_prefix\n",
    "    if kinship.shape[0] > 5000:\n",
    "        if sample_col == False:\n",
    "            kinship.drop(axis = 1, labels = [\"NWDID\"], inplace = True)\n",
    "        feather.write_dataframe(kinship, save_dir_filename_feather)\n",
    "    elif kinship.shape[0] <= 5000:\n",
    "        kinship.to_csv(save_dir_filename_tsv, sep = \"\\t\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_common_df(common_0, common_1, common_col, save_dir, file_type):\n",
    "    common_df_list = [common_0, common_1]\n",
    "    common_df = merge_df_list(common_df_list, common_col, merge_method='first')\n",
    "    common_df_filename = \"common_%s.tsv\"%file_type\n",
    "    common_df_dir_filename = os.path.join(save_dir, common_df_filename)\n",
    "    common_df.to_csv(common_df_dir_filename, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_gene_status_pc_pheno_kinship(status_name, cohort, freeze_ver, pc_num, common_col, kinship_df_ID,\n",
    "                                        snp_filename_list, snp_list, pheno_filename, status_filename, save_dir):\n",
    "    root_dir = os.path.join(\"..\", status_name, cohort)\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir, exist_ok = True) \n",
    "    snp_dir_filename_list = [os.path.join(\"..\", \"prepro_data\", \"snp\", snp_filename) for snp_filename in snp_filename_list]\n",
    "    pc_dir_filename = os.path.join(\"..\", \"prepro_data\", \"pc\", \"%s_pc%d_pcair.tsv\"%(freeze_ver, pc_num))\n",
    "    status_dir_filename = os.path.join(root_dir, \"pre_data\", status_filename)\n",
    "    pheno_dir_filename = os.path.join(root_dir, \"pre_data\", pheno_filename)\n",
    "    kinship_dir_filename = os.path.join(\"..\", \"prepro_data\", \"kinship\", \"%s_kinship_sample.tsv\"%freeze_ver)\n",
    "    snp_pc_cn_dir_filename_list = snp_dir_filename_list + [pc_dir_filename, status_dir_filename, pheno_dir_filename, kinship_dir_filename]\n",
    "    \n",
    "    snp_pc_cn_df = read2df_list(snp_pc_cn_dir_filename_list)\n",
    "    common_snp_0 = merge_df_list(snp_pc_cn_df, common_col, merge_method='first', how = 'inner')\n",
    "    \n",
    "    common_snp_0_filename = \"common_%s.tsv\"%snp_list[0]\n",
    "    common_snp_0_dir_filename = os.path.join(save_dir, common_snp_0_filename)\n",
    "    common_snp_0.to_csv(common_snp_0_dir_filename, sep=\"\\t\", index=False)\n",
    "    \n",
    "    sample_df = common_snp_0[[\"NWDID\"]]\n",
    "    sample_filename = \"common_sample.tsv\"\n",
    "    sample_dir_filename = os.path.join(save_dir, sample_filename)\n",
    "    sample_df.to_csv(sample_dir_filename, sep=\"\\t\", index=False)\n",
    "    \n",
    "    snp_num = len(snp_list)\n",
    "    for snp_idx in range(1, snp_num):\n",
    "        common_0 = snp_pc_cn_df[snp_idx]\n",
    "        common_1 = common_snp_0\n",
    "        file_type = snp_list[snp_idx]\n",
    "        save_common_df(common_0, common_1, common_col, save_dir, file_type)\n",
    "    \n",
    "    save_common_df(snp_pc_cn_df[snp_num], common_snp_0, common_col, save_dir, \"pc\")\n",
    "    save_common_df(snp_pc_cn_df[snp_num + 1], common_snp_0, common_col, save_dir, status_name)\n",
    "    save_common_df(snp_pc_cn_df[snp_num + 2], common_snp_0, common_col, save_dir, \"pheno\")\n",
    "    if status_name == \"cn\":\n",
    "        common_del = cn2del(snp_pc_cn_df[snp_num + 1])\n",
    "        save_common_df(common_del, common_snp_0, common_col, save_dir, \"del\")\n",
    "    \n",
    "    kinship_sample_selected = kinship_select_sample(kinship_df_ID, sample_df)\n",
    "    print(kinship_sample_selected.shape)\n",
    "    common_kinship_filename_prefix = \"common_kinship\"\n",
    "    save_kinship_simple(save_dir, common_kinship_filename_prefix, kinship_sample_selected, sample_col = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Kinship Matrix for Later Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 56s, sys: 5min 6s, total: 7min 2s\n",
      "Wall time: 6min 40s\n"
     ]
    }
   ],
   "source": [
    "predata_dir = os.path.join(\"..\", \"prepro_data\", \"kinship\")\n",
    "freeze8_kinship_filename = \"freeze8_kinship.feather\"\n",
    "freeze8_kinship_dir_filename = os.path.join(predata_dir, freeze8_kinship_filename)\n",
    "%time freeze8_kinship_df = pd.read_feather(freeze8_kinship_dir_filename, use_threads = True)\n",
    "freeze8_sample_list = list(freeze8_kinship_df)\n",
    "freeze8_sample_df = pd.DataFrame(data=freeze8_sample_list, columns=[\"NWDID\"])\n",
    "freeze8_kinship_df_ID = pd.concat(objs=[freeze8_sample_df, freeze8_kinship_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load rs2302524, rs2633317, rs4251805, rs4760, rs73935023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_ver = \"freeze8\"\n",
    "snp_dir = os.path.join(\"..\", \"raw_data\", \"snp\")\n",
    "save_dir = os.path.join(\"..\", \"prepro_data\", \"snp\")\n",
    "snp_id_dict = {\"rs2302524\":\"whole\", \"rs2633317\":\"whole\", \"rs4251805\":\"whole\", \"rs4760\":\"whole\", \"rs73935023\":\"whole\"}\n",
    "snp_dir_filename_list = [os.path.join(snp_dir, \"%s_%s.raw\"%(snp_ver, snp_id)) for snp_id in snp_id_dict]\n",
    "snp_df_list = save_snp_dict_each(snp_dir_filename_list, snp_id_dict, snp_ver, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load rs334, rs399145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/proj/yunligrp/users/minzhi/custom_lib/function_process_data_eqtl.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  snp_df.dropna(axis = 0, how = \"any\", inplace = True)\n"
     ]
    }
   ],
   "source": [
    "snp_ver = \"freeze8\"\n",
    "snp_dir = os.path.join(\"..\", \"raw_data\", \"snp\")\n",
    "save_dir = os.path.join(\"..\", \"prepro_data\", \"snp\")\n",
    "snp_id_dict = {\"rs334\":\"hetero\", \"rs399145\":\"whole\", \"rs11248850\":\"whole\"}\n",
    "snp_dir_filename_list = [os.path.join(snp_dir, \"%s_%s.raw\"%(snp_ver, snp_id)) for snp_id in snp_id_dict]\n",
    "snp_df_list = save_snp_dict_each(snp_dir_filename_list, snp_id_dict, snp_ver, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eGFR and APOL1 Status x Gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding CKD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_dir = os.path.join(\"..\", \"prepro_data\", \"phenotype\")\n",
    "pheno_filename = \"freeze8_anno05_af02_unique02_egfr.tsv\"\n",
    "pheno_dir_filename = os.path.join(pheno_dir, pheno_filename)\n",
    "pheno = pd.read_csv(pheno_dir_filename, sep = \"\\t\", header = 0, index_col = None)\n",
    "pheno_ckd = one_condition_conversion(pheno, \"EGFRCKDEPI\", 60, \"CKD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_ckd_dir = os.path.join(\"..\", \"prepro_data\", \"phenotype\")\n",
    "pheno_ckd_filename = \"freeze8_anno05_af02_unique02_egfr-ckd.tsv\"\n",
    "pheno_ckd_dir_filename = os.path.join(pheno_ckd_dir, pheno_ckd_filename)\n",
    "pheno_ckd.to_csv(pheno_ckd_dir_filename, sep = \"\\t\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting into Each Cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### egfr-ckd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "egfr_dir = os.path.join(\"..\", \"prepro_data\", \"phenotype\")\n",
    "egfr_filename = \"freeze8_anno05_af02_unique02_egfr-ckd.tsv\"\n",
    "egfr_dir_filename = os.path.join(egfr_dir, egfr_filename)\n",
    "egfr = pd.read_csv(pheno_ckd_dir_filename, sep = \"\\t\", header = 0, index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = egfr\n",
    "df = egfr\n",
    "cat_col = \"study\"\n",
    "anno_merge_col_list = [\"NWDID\"]\n",
    "df_merge_col_list = [\"NWDID\"]\n",
    "all_cohorts = True\n",
    "save_filename_prefix = \"freeze8_anno05_af02_unique02_egfr-ckd\"\n",
    "save_dir_root = os.path.join(\"..\", \"apol1\")\n",
    "save_dir_base = \"pre_data\"\n",
    "cohort_list = df_splitter(anno, df, cat_col, anno_merge_col_list, df_merge_col_list,\n",
    "                          all_cohorts, save_filename_prefix, save_dir_root, save_dir_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To \"all_cohorts\", same dataframe, but different size and loaded as two different dataframes (df1.equals(df2) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_dir_filename = \"/proj/yunligrp/users/minzhi/asso/apol1/all_cohorts/pre_data/freeze8_anno05_af02_unique02_egfr-ckd.tsv\"\n",
    "df2_dir_filename = \"/proj/yunligrp/users/minzhi/asso/apol1/all_cohorts/pre_data/freeze8_anno05_af02_unique02_egfr-ckd_all_cohorts.tsv\"\n",
    "df1 = pd.read_csv(df1_dir_filename, sep = \"\\t\", header = 0, index_col = None)\n",
    "df2 = pd.read_csv(df2_dir_filename, sep = \"\\t\", header = 0, index_col = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### APOL1 Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "apol1_dir = os.path.join(\"..\", \"prepro_data\", \"apol1\")\n",
    "apol1_filename = \"APOL1_status.tsv\"\n",
    "apol1_dir_filename = os.path.join(apol1_dir, apol1_filename)\n",
    "apol1 = pd.read_csv(apol1_dir_filename, sep = \"\\t\", header = 0, index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_dir = os.path.join(\"..\", \"prepro_data\", \"phenotype\")\n",
    "anno_filename = \"freeze8_anno05_af02_unique02_egfr-ckd.tsv\"\n",
    "anno_dir_filename = os.path.join(anno_dir, anno_filename)\n",
    "anno = pd.read_csv(anno_dir_filename, sep = \"\\t\", header = 0, index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apol1\n",
    "cat_col = \"study\"\n",
    "anno_merge_col_list = [\"NWDID\"]\n",
    "df_merge_col_list = [\"NWDID\"]\n",
    "all_cohorts = True\n",
    "save_filename_prefix = \"apol1\"\n",
    "save_dir_root = os.path.join(\"..\", \"apol1\")\n",
    "save_dir_base = \"pre_data\"\n",
    "cohort_list = df_splitter(anno, df, cat_col, anno_merge_col_list, df_merge_col_list,\n",
    "                          all_cohorts, save_filename_prefix, save_dir_root, save_dir_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Cohorts togeother vs. Multiple SNPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23885, 23886)\n",
      "all_cohorts common samples found.\n",
      "(23885, 23886)\n",
      "all_cohorts common samples found.\n",
      "(23885, 23886)\n",
      "all_cohorts common samples found.\n",
      "(23885, 23886)\n",
      "all_cohorts common samples found.\n",
      "(23885, 23886)\n",
      "all_cohorts common samples found.\n"
     ]
    }
   ],
   "source": [
    "status_name = \"apol1\"\n",
    "cohort_list = [\"all_cohorts\"]\n",
    "freeze_ver = \"freeze8\"\n",
    "pc_num = 11\n",
    "common_col = \"NWDID\"\n",
    "snp_id_dict_list = [{\"rs2302524\":\"whole\"}, {\"rs2633317\":\"whole\"}, {\"rs4251805\":\"whole\"}, {\"rs4760\":\"whole\"}, {\"rs73935023\":\"whole\"}]\n",
    "pheno_prefix = \"freeze8_anno05_af02_unique02_egfr-ckd\"\n",
    "\n",
    "for cohort in cohort_list:\n",
    "    pheno_filename = \"%s_%s.tsv\"%(pheno_prefix, cohort)\n",
    "    status_filename = \"%s_%s.tsv\"%(status_name, cohort)\n",
    "    for snp_id_dict in snp_id_dict_list:\n",
    "        snp_list = list(snp_id_dict.keys())\n",
    "        snp_id_string = \"_\".join(snp_list)\n",
    "        save_dir = os.path.join(\"..\", status_name, cohort, \"ready_data_%s\"%snp_id_string)\n",
    "        snp_filename_list = []\n",
    "        for snp_id in snp_id_dict:\n",
    "            snp_type = snp_id_dict[snp_id]\n",
    "            snp_filename = \"%s_%s_%s.tsv\"%(freeze_ver, snp_id, snp_type)\n",
    "            snp_filename_list.append(snp_filename)\n",
    "        common_gene_status_pc_pheno_kinship(status_name, cohort, freeze_ver, pc_num, common_col, freeze8_kinship_df_ID,\n",
    "                                            snp_filename_list, snp_list, pheno_filename, status_filename, save_dir)\n",
    "        print(\"%s common samples found.\"%cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genxgen(gen_1, gen_2, gen_1_name, gen_2_name, common_col, save_dir):\n",
    "#     gen_gen = pd.concat(objs=[gen_1, gen_2[[gen_2_name]]], axis=1)\n",
    "    gen_gen = gen_1.merge(gen_2, on = common_col, how = \"inner\")\n",
    "    gen_gen[\"%s-%s\"%(gen_1_name, gen_2_name)] = gen_gen[gen_1_name] * gen_gen[gen_2_name]\n",
    "    rearrange_list = [list(gen_gen)[0]] + [\"%s-%s\"%(gen_1_name, gen_2_name), gen_1_name, gen_2_name]\n",
    "    gen_gen_rearrange = gen_gen.copy()\n",
    "    gen_gen_rearrange = gen_gen[rearrange_list]\n",
    "    gen_gen_rearrange_filename = \"common_%s-%s.tsv\"%(gen_1_name, gen_2_name)\n",
    "    gen_gen_rearrange_dir_filename = os.path.join(save_dir, gen_gen_rearrange_filename)\n",
    "    gen_gen_rearrange.to_csv(gen_gen_rearrange_dir_filename, sep = \"\\t\", header = True, index = False)\n",
    "    return gen_gen_rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_univar_interact(cohort, gen_name, status_name, load_dir):\n",
    "    save_dir = load_dir\n",
    "    status_filename = \"common_%s.tsv\"%status_name\n",
    "    status_dir_filename = os.path.join(load_dir, status_filename)\n",
    "    status = pd.read_csv(status_dir_filename, sep=\"\\t\", header = 0, index_col = None)\n",
    "    \n",
    "    gen_filename = \"common_%s.tsv\"%gen_name\n",
    "    gen_dir_filename = os.path.join(load_dir, gen_filename)\n",
    "    gen = pd.read_csv(gen_dir_filename, sep = \"\\t\", header = 0, index_col = None)\n",
    "    \n",
    "    status_gen = genxgen(status, gen, status_name, gen_name, common_col, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_matrix_pheno_adad_in_pheno(status_name, cohort, phenotype, pheno_full_df, var_name, var_df, table_name,\n",
    "                                       kinship_df_ID, pc10_df, adad_header):\n",
    "    if not os.path.exists(os.path.join(\"..\", status_name, cohort, table_name)):\n",
    "        os.mkdir(os.path.join(\"..\", status_name, cohort, table_name))\n",
    "    if not os.path.exists(os.path.join(\"..\", status_name, cohort, table_name, var_name)):\n",
    "        os.mkdir(os.path.join(\"..\", status_name, cohort, table_name, var_name))\n",
    "        \n",
    "    save_dir = os.path.join(\"..\", status_name, cohort, table_name, var_name)\n",
    "    \n",
    "    pheno_df_raw = pheno_full_df[[\"NWDID\", \"sex\", phenotype, \"age_at_%s\"%phenotype] + adad_header].copy()\n",
    "    pheno_df_raw.dropna(axis = 1, how = \"all\", inplace = True)\n",
    "    adad_header_used = intersection_list(list(pheno_df_raw), adad_header)\n",
    "    if phenotype not in list(pheno_df_raw):\n",
    "        return None\n",
    "    \n",
    "    pheno_agesex_df = pheno_df_raw.dropna(axis=0)\n",
    "    common_col = \"NWDID\"\n",
    "    pheno_agesex_var_df_list = [pheno_agesex_df, var_df]\n",
    "    common_pheno_agesex = merge_df_list(pheno_agesex_var_df_list, common_col, merge_method='first')\n",
    "    common_var = merge_df_list(pheno_agesex_var_df_list, common_col, merge_method='second')\n",
    "    sample_df = common_pheno_agesex[[\"NWDID\"]].copy()\n",
    "    \n",
    "    common_pheno = common_pheno_agesex[[\"NWDID\", phenotype]].copy()\n",
    "    common_pheno_filename = \"common_pheno_%s_%s_%s.tsv\"%(table_name, var_name, phenotype)\n",
    "    common_pheno_dir_filename = os.path.join(save_dir, common_pheno_filename)\n",
    "    common_pheno.to_csv(common_pheno_dir_filename, sep=\"\\t\", index=False)\n",
    "    \n",
    "    common_var_filename = \"common_var_%s_%s_%s.tsv\"%(table_name, var_name, phenotype)\n",
    "    common_var_dir_filename = os.path.join(save_dir, common_var_filename)\n",
    "    common_var.to_csv(common_var_dir_filename, sep=\"\\t\", index=False)\n",
    "\n",
    "    common_kinship = kinship_select_sample(kinship_df_ID, sample_df)\n",
    "    common_kinship_filename_prefix = \"common_kinship_%s_%s_%s\"%(table_name, var_name, phenotype)\n",
    "    save_kinship_simple(save_dir, common_kinship_filename_prefix, common_kinship, sample_col = False)\n",
    "\n",
    "    common_age_sex = common_pheno_agesex[[\"NWDID\", \"age_at_%s\"%phenotype, \"sex\"] + adad_header_used].copy()\n",
    "    common_age_sex_filename = \"common_age-sex_%s_%s_%s.tsv\"%(table_name, var_name, phenotype)\n",
    "    common_age_sex_dir_filename = os.path.join(save_dir, common_age_sex_filename)\n",
    "    common_age_sex.to_csv(common_age_sex_dir_filename, sep=\"\\t\", index=False)\n",
    "    \n",
    "    common_pc10 = merge_df_list([pc10_df, sample_df], common_col, merge_method='first')\n",
    "    common_pc10_filename = \"common_pc10_%s_%s_%s.tsv\"%(table_name, var_name, phenotype)\n",
    "    common_pc10_dir_filename = os.path.join(save_dir, common_pc10_filename)\n",
    "    common_pc10.to_csv(common_pc10_dir_filename, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_prepare_matrix_pheno_adad_in_pheno(status_name, phenotype_list, table_dict, load_dir, adad_dict):\n",
    "    for table_name in table_dict:\n",
    "        pheno_full_filename = \"common_pheno.tsv\"\n",
    "        pheno_full_dir_filename = os.path.join(load_dir, pheno_full_filename)\n",
    "        pheno_full_df = pd.read_csv(pheno_full_dir_filename, sep=\"\\t\")\n",
    "        if bool(adad_dict):\n",
    "            pheno_full_df_raw = pheno_full_df.copy()\n",
    "            del pheno_full_df\n",
    "            pheno_full_df, adad_header = adad_header_conversion(pheno_full_df_raw, adad_dict)\n",
    "            pheno_dummy_adad_filename = \"common_pheno_adad_dummy.tsv\"\n",
    "            pheno_dummy_adad_dir_filename = os.path.join(load_dir, pheno_dummy_adad_filename)\n",
    "            pheno_full_df.to_csv(pheno_dummy_adad_dir_filename, sep = \"\\t\", header = True, index = False)\n",
    "        else:\n",
    "            adad_header = []\n",
    "        \n",
    "        kinship_filename_prefix = \"common_kinship\"\n",
    "        kinship_df_ID = load_kinship_simple(load_dir, kinship_filename_prefix)\n",
    "\n",
    "        pc_filename = \"common_pc.tsv\"\n",
    "        pc_dir_filename = os.path.join(load_dir, pc_filename)\n",
    "        pc_df = pd.read_csv(pc_dir_filename, sep=\"\\t\")\n",
    "        \n",
    "        var_name_list = table_dict[table_name]\n",
    "        for var_name in var_name_list:\n",
    "            var_filename = \"common_%s.tsv\"%var_name\n",
    "            var_dir_filename = os.path.join(load_dir, var_filename)\n",
    "            var_df = pd.read_csv(var_dir_filename, sep=\"\\t\")\n",
    "        \n",
    "            for phenotype, i in zip(phenotype_list, range(len(phenotype_list))):\n",
    "                prepare_matrix_pheno_adad_in_pheno(status_name, cohort, phenotype, pheno_full_df, var_name, var_df, table_name,\n",
    "                                                   kinship_df_ID, pc_df, adad_header)\n",
    "#                print(\"%s (%d/%d) completed.\"%(phenotype, i + 1, len(phenotype_list)))\n",
    "        print(\"%s completed.\"%table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adad_header_conversion(df_original, adad_dict):\n",
    "    adad_quan_list = adad_dict[\"quan\"]\n",
    "    adad_cati_list = adad_dict[\"cati\"]\n",
    "    df, _, adad_cati_dummy_list = cati2dummy_df(df_original, adad_cati_list)\n",
    "    adad_header = adad_quan_list + adad_cati_dummy_list\n",
    "    return df, adad_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs2302524 completed.\n",
      "rs2633317 completed.\n",
      "rs4251805 completed.\n",
      "rs4760 completed.\n",
      "rs73935023 completed.\n",
      "all_cohorts completed.\n"
     ]
    }
   ],
   "source": [
    "status_name = \"apol1\"\n",
    "cohort_list = [\"all_cohorts\"]\n",
    "common_col = \"NWDID\"\n",
    "snp_id_dict_list = [{\"rs2302524\":\"whole\"}, {\"rs2633317\":\"whole\"}, {\"rs4251805\":\"whole\"}, {\"rs4760\":\"whole\"}, {\"rs73935023\":\"whole\"}]\n",
    "\n",
    "phenotype_list = [\"EGFRCKDEPI\", \"CKD\"]\n",
    "table_dict_list = [{\"rs2302524\":[\"rs2302524\", \"apol1-rs2302524\"]}, {\"rs2633317\":[\"rs2633317\", \"apol1-rs2633317\"]},\n",
    "                   {\"rs4251805\":[\"rs4251805\", \"apol1-rs4251805\"]}, {\"rs4760\":[\"rs4760\", \"apol1-rs4760\"]},\n",
    "                   {\"rs73935023\":[\"rs73935023\", \"apol1-rs73935023\"]}]\n",
    "adad_dict = {\"quan\":[], \"cati\":[\"AA\", \"ethnicity\", \"study\"]}\n",
    "\n",
    "for cohort in cohort_list:\n",
    "    for table_dict, snp_id_dict in zip(table_dict_list, snp_id_dict_list):\n",
    "        snp_id_list = list(snp_id_dict.keys())\n",
    "        snp_id_string = \"_\".join(snp_id_list)\n",
    "        \n",
    "        load_dir = os.path.join(\"..\", status_name, cohort, \"ready_data_%s\"%snp_id_string)\n",
    "        gen_name = snp_id_string\n",
    "        table_univar_interact(cohort, gen_name, status_name, load_dir)\n",
    "        wrap_prepare_matrix_pheno_adad_in_pheno(status_name, phenotype_list, table_dict, load_dir, adad_dict)\n",
    "    print(\"%s completed.\"%cohort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each Cohorts vs. rs334 and rs399145"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 376)\n",
      "DHS common samples found.\n",
      "(1612, 1613)\n",
      "WHI common samples found.\n",
      "(709, 710)\n",
      "CHS common samples found.\n",
      "(1682, 1683)\n",
      "ARIC common samples found.\n",
      "(3132, 3133)\n",
      "JHS common samples found.\n",
      "(1090, 1091)\n",
      "MESA common samples found.\n",
      "(7708, 7709)\n",
      "HCHS_SOL common samples found.\n",
      "(205, 206)\n",
      "GeneSTAR common samples found.\n",
      "(1844, 1845)\n",
      "HyperGEN common samples found.\n",
      "(1091, 1092)\n",
      "GENOA common samples found.\n",
      "(3413, 3414)\n",
      "FHS common samples found.\n",
      "(1014, 1015)\n",
      "CARDIA common samples found.\n"
     ]
    }
   ],
   "source": [
    "egfr_dir = os.path.join(\"..\", \"prepro_data\", \"phenotype\")\n",
    "egfr_filename = \"freeze8_anno05_af02_unique02_egfr-ckd.tsv\"\n",
    "egfr_dir_filename = os.path.join(egfr_dir, egfr_filename)\n",
    "egfr = pd.read_csv(egfr_dir_filename, sep = \"\\t\", header = 0, index_col = None)\n",
    "_, cohort_list = categorize_df(egfr, \"study\")\n",
    "\n",
    "status_name = \"apol1\"\n",
    "freeze_ver = \"freeze8\"\n",
    "pc_num = 11\n",
    "common_col = \"NWDID\"\n",
    "snp_id_dict_list = [{\"rs334\":\"hetero\", \"rs399145\":\"whole\", \"rs11248850\":\"whole\"}]\n",
    "pheno_prefix = \"freeze8_anno05_af02_unique02_egfr-ckd\"\n",
    "\n",
    "for cohort in cohort_list:\n",
    "    pheno_filename = \"%s_%s.tsv\"%(pheno_prefix, cohort)\n",
    "    status_filename = \"%s_%s.tsv\"%(status_name, cohort)\n",
    "    for snp_id_dict in snp_id_dict_list:\n",
    "        snp_list = list(snp_id_dict.keys())\n",
    "        snp_id_string = \"_\".join(snp_list)\n",
    "        save_dir = os.path.join(\"..\", status_name, cohort, \"ready_data_%s\"%snp_id_string)\n",
    "        snp_filename_list = []\n",
    "        for snp_id in snp_id_dict:\n",
    "            snp_type = snp_id_dict[snp_id]\n",
    "            snp_filename = \"%s_%s_%s.tsv\"%(freeze_ver, snp_id, snp_type)\n",
    "            snp_filename_list.append(snp_filename)\n",
    "        common_gene_status_pc_pheno_kinship(status_name, cohort, freeze_ver, pc_num, common_col, freeze8_kinship_df_ID,\n",
    "                                            snp_filename_list, snp_list, pheno_filename, status_filename, save_dir)\n",
    "        print(\"%s common samples found.\"%cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_apol1(cohort, gen_name_list, status_name, common_col, load_dir):\n",
    "    save_dir = load_dir\n",
    "    status_filename = \"common_%s.tsv\"%status_name\n",
    "    status_dir_filename = os.path.join(load_dir, status_filename)\n",
    "    status = pd.read_csv(status_dir_filename, sep=\"\\t\", header = 0, index_col = None)\n",
    "    \n",
    "    gen_list = []\n",
    "    for gen_name in gen_name_list:\n",
    "        gen_filename = \"common_%s.tsv\"%gen_name\n",
    "        gen_dir_filename = os.path.join(load_dir, gen_filename)\n",
    "        gen = pd.read_csv(gen_dir_filename, sep = \"\\t\", header = 0, index_col = None)\n",
    "        genxgen(status, gen, status_name, gen_name, common_col, save_dir)\n",
    "        gen_list.append(gen)\n",
    "        \n",
    "    genxgen(gen_list[0], gen_list[1], gen_name_list[0], gen_name_list[1], common_col, save_dir)\n",
    "    genxgen(gen_list[0], gen_list[2], gen_name_list[0], gen_name_list[2], common_col, save_dir)\n",
    "    genxgen(gen_list[1], gen_list[2], gen_name_list[1], gen_name_list[2], common_col, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_apol1 completed.\n",
      "GeneSTAR completed.\n",
      "table_apol1 completed.\n",
      "GENOA completed.\n",
      "table_apol1 completed.\n",
      "HyperGEN completed.\n",
      "table_apol1 completed.\n",
      "WHI completed.\n",
      "table_apol1 completed.\n",
      "ARIC completed.\n",
      "table_apol1 completed.\n",
      "CARDIA completed.\n",
      "table_apol1 completed.\n",
      "JHS completed.\n",
      "table_apol1 completed.\n",
      "CHS completed.\n",
      "table_apol1 completed.\n",
      "HCHS_SOL completed.\n",
      "table_apol1 completed.\n",
      "FHS completed.\n",
      "table_apol1 completed.\n",
      "MESA completed.\n",
      "table_apol1 completed.\n",
      "DHS completed.\n"
     ]
    }
   ],
   "source": [
    "egfr_dir = os.path.join(\"..\", \"prepro_data\", \"phenotype\")\n",
    "egfr_filename = \"freeze8_anno05_af02_unique02_egfr-ckd.tsv\"\n",
    "egfr_dir_filename = os.path.join(egfr_dir, egfr_filename)\n",
    "egfr = pd.read_csv(egfr_dir_filename, sep = \"\\t\", header = 0, index_col = None)\n",
    "_, cohort_list = categorize_df(egfr, \"study\")\n",
    "\n",
    "status_name = \"apol1\"\n",
    "common_col = \"NWDID\"\n",
    "snp_id_dict_list = [{\"rs334\":\"hetero\", \"rs399145\":\"whole\", \"rs11248850\":\"whole\"}]\n",
    "\n",
    "phenotype_list = [\"EGFRCKDEPI\", \"CKD\"]\n",
    "table_dict_list = [{\"table_apol1\":[\"rs334\", \"rs399145\", \"rs11248850\", \"apol1-rs334\", \"apol1-rs399145\", \"apol1-rs11248850\",\n",
    "                                   \"rs334-rs399145\", \"rs334-rs11248850\", \"rs399145-rs11248850\"]}]\n",
    "adad_dict = {\"quan\":[], \"cati\":[\"AA\", \"ethnicity\"]}\n",
    "\n",
    "for cohort in cohort_list:\n",
    "    for table_dict, snp_id_dict in zip(table_dict_list, snp_id_dict_list):\n",
    "        snp_id_list = list(snp_id_dict.keys())\n",
    "        snp_id_string = \"_\".join(snp_id_list)\n",
    "        \n",
    "        load_dir = os.path.join(\"..\", status_name, cohort, \"ready_data_%s\"%snp_id_string)\n",
    "        gen_name = snp_id_string\n",
    "        table_apol1(cohort, snp_id_list, status_name, common_col, load_dir)\n",
    "        wrap_prepare_matrix_pheno_adad_in_pheno(status_name, phenotype_list, table_dict, load_dir, adad_dict)\n",
    "    print(\"%s completed.\"%cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GeneSTAR', 'GENOA', 'HyperGEN', 'WHI', 'ARIC', 'CARDIA', 'JHS', 'CHS', 'HCHS_SOL', 'FHS', 'MESA', 'DHS']\n"
     ]
    }
   ],
   "source": [
    "print(cohort_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Each Type of APOL1 Status, rs334, rs399145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = \"APOL1\"\n",
    "load_dir = os.path.join(\"..\", \"cohort\", cohort, \"ready_data\")\n",
    "apol1_filename = \"common_status.tsv\"\n",
    "apol1_dir_filename = os.path.join(load_dir, apol1_filename)\n",
    "apol1 = pd.read_csv(apol1_dir_filename, sep=\"\\t\")\n",
    "\n",
    "rs334_filename = \"common_rs334.tsv\"\n",
    "rs334_dir_filename = os.path.join(load_dir, rs334_filename)\n",
    "rs334 = pd.read_csv(rs334_dir_filename, sep=\"\\t\")\n",
    "\n",
    "rs399145_filename = \"common_rs399145.tsv\"\n",
    "rs399145_dir_filename = os.path.join(load_dir, rs399145_filename)\n",
    "rs399145 = pd.read_csv(rs399145_dir_filename, sep=\"\\t\")\n",
    "\n",
    "egfr_filename = \"common_pheno_adad_dummy.tsv\"\n",
    "egfr_dir_filename = os.path.join(load_dir, egfr_filename)\n",
    "egfr = pd.read_csv(egfr_dir_filename, sep = \"\\t\", header = 0, index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {\"APOL1\":apol1, \"rs334\":rs334, \"rs399145\":rs399145}\n",
    "common_col = \"NWDID\"\n",
    "save_dir = os.path.join(\"..\", \"data_summary\")\n",
    "value_tuple = (egfr, \"EGFRCKDEPI\")\n",
    "df_name_list = [\"APOL1\", \"rs334\", \"rs399145\"]\n",
    "for case_col_list in list(combinations(df_name_list,2)):\n",
    "    df_list = [df_dict[case_col_list[0]], df_dict[case_col_list[1]]]\n",
    "    overlap_num_df, overlap_value_df = overlap_num_all_cases(df_list, case_col_list, common_col, save_dir, value_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
