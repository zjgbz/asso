{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import feather\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error \n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"/proj/yunligrp/users/minzhi/custom_lib\" not in sys.path:\n",
    "    sys.path.insert(0, \"/proj/yunligrp/users/minzhi/custom_lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function_process_data_eqtl import *\n",
    "from function_asso import *\n",
    "from function_mesa_cca import *\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_splitter(anno, df, cat_col, anno_merge_col_list, df_merge_col_list, all_cohorts, save_filename_prefix, save_dir_root, save_dir_base):\n",
    "    if anno.equals(df):\n",
    "        anno_df = copy.copy(anno)\n",
    "    else:\n",
    "        anno_df = anno.merge(df, left_on = anno_merge_col_list, right_on = df_merge_col_list, how = \"inner\")\n",
    "    _, cohort_list = categorize_df(anno_df, cat_col)\n",
    "    if all_cohorts == True:\n",
    "        cohort_list.append(\"all_cohorts\")\n",
    "    \n",
    "    for cohort in cohort_list:\n",
    "        if cohort == \"all_cohorts\":\n",
    "            df_cohort_raw = copy.copy(anno_df)\n",
    "        else:\n",
    "            df_cohort_raw = anno_df.loc[anno_df.loc[:, cat_col] == cohort, :]\n",
    "        df_id = df_cohort_raw[df_merge_col_list]\n",
    "        df_cohort = df.merge(df_id, on = df_merge_col_list, how = \"inner\")\n",
    "        df_cohort_filename = \"%s_%s.tsv\"%(save_filename_prefix, cohort)\n",
    "        save_dir = os.path.join(save_dir_root, cohort, save_dir_base)\n",
    "        df_cohort_dir_filename = os.path.join(save_dir, df_cohort_filename)\n",
    "        if not os.path.isdir(save_dir):\n",
    "            os.makedirs(save_dir, exist_ok = True)\n",
    "        df_cohort.to_csv(df_cohort_dir_filename, sep = \"\\t\", header = True, index = False)\n",
    "    return cohort_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_gene_status_pc_pheno_kinship(status_name, cohort, freeze_ver, gpc_num, common_col, snp_dict, pheno_prefix, kinship_df_ID):\n",
    "    root_dir = os.path.join(\"..\", status_name, cohort)\n",
    "    save_dir = os.path.join(root_dir, \"ready_data\")\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir, exist_ok = True) \n",
    "    snp_dir_filename_list = [os.path.join(\"..\", \"prepro_data\", \"snp\", \"%s_%s_%s.tsv\"%(freeze_ver, snp_i, snp_selection)) for snp_i in snp_list]\n",
    "    pc_dir_filename = os.path.join(\"..\", \"prepro_data\", \"pc\", \"%s_pc%d_pcair.tsv\"%(freeze_ver, pc_num))\n",
    "    status_dir_filename = os.path.join(root_dir, \"pre_data\", \"%s_%s.tsv\"%(cohort, cn_var))\n",
    "    pheno_dir_filename = os.path.join(\"..\", \"cohort\", cohort, \"pre_data\", \"%s_%s.tsv\"%(pheno_prefix, cohort))\n",
    "    kinship_dir_filename = os.path.join(\"..\", \"prepro_data\", \"kinship\", \"%s_kinship_sample.tsv\"%freeze_ver)\n",
    "    snp_pc_cn_dir_filename_list = snp_dir_filename_list + [pc_dir_filename, cn_dir_filename, pheno_dir_filename, kinship_dir_filename]\n",
    "    \n",
    "    snp_pc_cn_df = read2df_list(snp_pc_cn_dir_filename_list)\n",
    "    common_snp_0 = merge_df_list(snp_pc_cn_df, common_col, merge_method='first', how = 'inner')\n",
    "    \n",
    "    common_snp_0_filename = \"common_%s.tsv\"%snp_list[0]\n",
    "    common_snp_0_dir_filename = os.path.join(save_dir, common_snp_0_filename)\n",
    "    common_snp_0.to_csv(common_snp_0_dir_filename, sep=\"\\t\", index=False)\n",
    "    \n",
    "    sample_df = common_snp_0[[\"NWDID\"]]\n",
    "    sample_filename = \"common_sample.tsv\"\n",
    "    sample_dir_filename = os.path.join(save_dir, sample_filename)\n",
    "    sample_df.to_csv(sample_dir_filename, sep=\"\\t\", index=False)\n",
    "    \n",
    "    snp_num = len(snp_list)\n",
    "    for snp_idx in range(1, snp_num):\n",
    "        common_0 = snp_pc_cn_df[snp_idx]\n",
    "        common_1 = common_snp_0\n",
    "        file_type = snp_list[snp_idx]\n",
    "        save_common_df(common_0, common_1, common_col, save_dir, file_type)\n",
    "    \n",
    "    save_common_df(snp_pc_cn_df[snp_num], common_snp_0, common_col, save_dir, \"pc\")\n",
    "    save_common_df(snp_pc_cn_df[snp_num + 1], common_snp_0, common_col, save_dir, cn_var)\n",
    "    save_common_df(snp_pc_cn_df[snp_num + 2], common_snp_0, common_col, save_dir, \"pheno\")\n",
    "    if cn_var == \"cn\":\n",
    "        common_del = cn2del(snp_pc_cn_df[snp_num + 1])\n",
    "        save_common_df(common_del, common_snp_0, common_col, save_dir, \"del\")\n",
    "    \n",
    "    kinship_sample_selected = kinship_select_sample(kinship_df_ID, sample_df)\n",
    "    print(kinship_sample_selected.shape)\n",
    "    common_kinship_filename_prefix = \"common_kinship\"\n",
    "    save_kinship_simple(save_dir, common_kinship_filename_prefix, kinship_sample_selected, sample_col = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Kinship Matrix for Later Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 5min 48s, total: 7min 25s\n",
      "Wall time: 10min 54s\n"
     ]
    }
   ],
   "source": [
    "predata_dir = os.path.join(\"..\", \"prepro_data\", \"kinship\")\n",
    "freeze8_kinship_filename = \"freeze8_kinship.feather\"\n",
    "freeze8_kinship_dir_filename = os.path.join(predata_dir, freeze8_kinship_filename)\n",
    "%time freeze8_kinship_df = pd.read_feather(freeze8_kinship_dir_filename, use_threads = True)\n",
    "freeze8_sample_list = list(freeze8_kinship_df)\n",
    "freeze8_sample_df = pd.DataFrame(data=freeze8_sample_list, columns=[\"NWDID\"])\n",
    "freeze8_kinship_df_ID = pd.concat(objs=[freeze8_sample_df, freeze8_kinship_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load rs2302524, rs2633317, rs4251805, rs4760, rs73935023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../eqtl/eqtl_script/function_process_data_eqtl.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  snp_df.dropna(axis = 0, how = \"any\", inplace = True)\n"
     ]
    }
   ],
   "source": [
    "snp_ver = \"freeze8\"\n",
    "snp_dir = os.path.join(\"..\", \"raw_data\", \"snp\")\n",
    "snp_id_list = [\"rs2302524\", \"rs2633317\", \"rs4251805\", \"rs4760\", \"rs73935023\"]\n",
    "snp_dir_filename_list = [os.path.join(snp_dir, \"%s_%s.raw\"%(snp_ver, snp_id)) for snp_id in snp_id_list]\n",
    "snp_list = read_snp_list_each(snp_dir_filename_list, snp_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eGFR and APOL1 Status x Gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding CKD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_dir = os.path.join(\"..\", \"prepro_data\", \"phenotype\")\n",
    "pheno_filename = \"freeze8_anno05_af02_unique02_egfr.tsv\"\n",
    "pheno_dir_filename = os.path.join(pheno_dir, pheno_filename)\n",
    "pheno = pd.read_csv(pheno_dir_filename, sep = \"\\t\", header = 0, index_col = None)\n",
    "pheno_ckd = one_condition_conversion(pheno, \"EGFRCKDEPI\", 60, \"CKD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_ckd_dir = os.path.join(\"..\", \"prepro_data\", \"phenotype\")\n",
    "pheno_ckd_filename = \"freeze8_anno05_af02_unique02_egfr-ckd.tsv\"\n",
    "pheno_ckd_dir_filename = os.path.join(pheno_ckd_dir, pheno_ckd_filename)\n",
    "pheno_ckd.to_csv(pheno_ckd_dir_filename, sep = \"\\t\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting into Each Cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### egfr-ckd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "egfr_dir = os.path.join(\"..\", \"prepro_data\", \"phenotype\")\n",
    "egfr_filename = \"freeze8_anno05_af02_unique02_egfr-ckd.tsv\"\n",
    "egfr_dir_filename = os.path.join(egfr_dir, egfr_filename)\n",
    "egfr = pd.read_csv(pheno_ckd_dir_filename, sep = \"\\t\", header = 0, index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = egfr\n",
    "df = egfr\n",
    "cat_col = \"study\"\n",
    "anno_merge_col_list = [\"NWDID\"]\n",
    "df_merge_col_list = [\"NWDID\"]\n",
    "all_cohorts = True\n",
    "save_filename_prefix = \"freeze8_anno05_af02_unique02_egfr-ckd\"\n",
    "save_dir_root = os.path.join(\"..\", \"apol1\")\n",
    "save_dir_base = \"pre_data\"\n",
    "cohort_list = df_splitter(anno, df, cat_col, anno_merge_col_list, df_merge_col_list, all_cohorts, save_filename_prefix, save_dir_root, save_dir_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To \"all_cohorts\", same dataframe, but different size and loaded as two different dataframes (df1.equals(df2) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_dir_filename = \"/proj/yunligrp/users/minzhi/asso/apol1/all_cohorts/pre_data/freeze8_anno05_af02_unique02_egfr-ckd.tsv\"\n",
    "df2_dir_filename = \"/proj/yunligrp/users/minzhi/asso/apol1/all_cohorts/pre_data/freeze8_anno05_af02_unique02_egfr-ckd_all_cohorts.tsv\"\n",
    "df1 = pd.read_csv(df1_dir_filename, sep = \"\\t\", header = 0, index_col = None)\n",
    "df2 = pd.read_csv(df2_dir_filename, sep = \"\\t\", header = 0, index_col = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### APOL1 Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "apol1_dir = os.path.join(\"..\", \"prepro_data\", \"apol1\")\n",
    "apol1_filename = \"APOL1_status.tsv\"\n",
    "apol1_dir_filename = os.path.join(apol1_dir, apol1_filename)\n",
    "apol1 = pd.read_csv(apol1_dir_filename, sep = \"\\t\", header = 0, index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_dir = os.path.join(\"..\", \"raw_data\", \"annotation\")\n",
    "anno_filename = \"freeze8_anno05_af02_unique02.tsv\"\n",
    "anno_dir_filename = os.path.join(anno_dir, anno_filename)\n",
    "anno = pd.read_csv(anno_dir_filename, sep = \"\\t\", header = 0, index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apol1\n",
    "cat_col = \"study\"\n",
    "anno_merge_col_list = [\"NWDID\"]\n",
    "df_merge_col_list = [\"NWDID\"]\n",
    "all_cohorts = True\n",
    "save_filename_prefix = \"apol1\"\n",
    "save_dir_root = os.path.join(\"..\", \"apol1\")\n",
    "save_dir_base = \"pre_data\"\n",
    "cohort_list = df_splitter(anno, df, cat_col, anno_merge_col_list, df_merge_col_list, all_cohorts, save_filename_prefix, save_dir_root, save_dir_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_list = [\"rs2302524\", \"rs2633317\", \"rs4251805\", \"rs4760\", \"rs73935023\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23877, 23878)\n"
     ]
    }
   ],
   "source": [
    "cohort = \"APOL1\"\n",
    "freeze_ver = \"freeze8\"\n",
    "pc_num = 11\n",
    "common_col = \"NWDID\"\n",
    "snp_list = [\"rs334\", \"rs399145\"]\n",
    "cn_var = \"status\"\n",
    "pheno_prefix = \"freeze8_2019-10-08_useful_unique02_egfr-ckd.tsv\"\n",
    "load_dir = os.path.join(\"..\", \"APOL1\", \"all_cohorts\", snp_id)\n",
    "if os.path.exists(load_dir)\n",
    "common_snp_pc_cn_pheno_kinship(cohort, freeze_ver, pc_num, common_col, snp_list, freeze8_kinship_df_ID, cn_var, pheno_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APOL1 Status x rs334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = \"APOL1\"\n",
    "load_dir = os.path.join(\"..\", \"cohort\", cohort, \"ready_data\")\n",
    "apol1_filename = \"common_status.tsv\"\n",
    "apol1_dir_filename = os.path.join(load_dir, apol1_filename)\n",
    "apol1 = pd.read_csv(apol1_dir_filename, sep=\"\\t\")\n",
    "\n",
    "rs334_filename = \"common_rs334.tsv\"\n",
    "rs334_dir_filename = os.path.join(load_dir, rs334_filename)\n",
    "rs334 = pd.read_csv(rs334_dir_filename, sep=\"\\t\")\n",
    "\n",
    "rs399145_filename = \"common_rs399145.tsv\"\n",
    "rs399145_dir_filename = os.path.join(load_dir, rs399145_filename)\n",
    "rs399145 = pd.read_csv(rs399145_dir_filename, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs399145_rs334_x = genxgen(rs399145, rs334, \"rs399145\", \"rs334\", \"NWDID\", load_dir)\n",
    "APOL1_rs334_x = genxgen(apol1, rs334, \"APOL1\", \"rs334\", \"NWDID\", load_dir)\n",
    "APOL1_rs399145_x = genxgen(apol1, rs399145, \"APOL1\", \"rs399145\", \"NWDID\", load_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table1 completed.\n",
      "APOL1 completed.\n"
     ]
    }
   ],
   "source": [
    "cohort = \"APOL1\"\n",
    "cn_var = \"status\"\n",
    "\n",
    "phenotype_list = [\"EGFRCKDEPI\", \"CKD\"]\n",
    "# table_dict = {\"table1\":[\"rs399145\", \"rs399145-rs334\", \"APOL1-rs334\"]}\n",
    "table_dict = {\"table1\":[\"APOL1-rs399145\"]}\n",
    "adad_dict = {\"quan\":[], \"cati\":[\"AA\", \"ethnicity\", \"study\"]}\n",
    "\n",
    "load_dir = os.path.join(\"..\", \"cohort\", cohort, \"ready_data\")\n",
    "wrap_prepare_matrix_pheno_adad_in_pheno(phenotype_list, table_dict, load_dir, adad_dict)\n",
    "print(\"%s completed.\"%cohort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Each Type of APOL1 Status, rs334, rs399145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = \"APOL1\"\n",
    "load_dir = os.path.join(\"..\", \"cohort\", cohort, \"ready_data\")\n",
    "apol1_filename = \"common_status.tsv\"\n",
    "apol1_dir_filename = os.path.join(load_dir, apol1_filename)\n",
    "apol1 = pd.read_csv(apol1_dir_filename, sep=\"\\t\")\n",
    "\n",
    "rs334_filename = \"common_rs334.tsv\"\n",
    "rs334_dir_filename = os.path.join(load_dir, rs334_filename)\n",
    "rs334 = pd.read_csv(rs334_dir_filename, sep=\"\\t\")\n",
    "\n",
    "rs399145_filename = \"common_rs399145.tsv\"\n",
    "rs399145_dir_filename = os.path.join(load_dir, rs399145_filename)\n",
    "rs399145 = pd.read_csv(rs399145_dir_filename, sep=\"\\t\")\n",
    "\n",
    "egfr_filename = \"common_pheno_adad_dummy.tsv\"\n",
    "egfr_dir_filename = os.path.join(load_dir, egfr_filename)\n",
    "egfr = pd.read_csv(egfr_dir_filename, sep = \"\\t\", header = 0, index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {\"APOL1\":apol1, \"rs334\":rs334, \"rs399145\":rs399145}\n",
    "common_col = \"NWDID\"\n",
    "save_dir = os.path.join(\"..\", \"data_summary\")\n",
    "value_tuple = (egfr, \"EGFRCKDEPI\")\n",
    "df_name_list = [\"APOL1\", \"rs334\", \"rs399145\"]\n",
    "for case_col_list in list(combinations(df_name_list,2)):\n",
    "    df_list = [df_dict[case_col_list[0]], df_dict[case_col_list[1]]]\n",
    "    overlap_num_df, overlap_value_df = overlap_num_all_cases(df_list, case_col_list, common_col, save_dir, value_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
