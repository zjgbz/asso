{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import feather\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error \n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"/proj/yunligrp/users/minzhi/custom_lib\" not in sys.path:\n",
    "    sys.path.insert(0, \"/proj/yunligrp/users/minzhi/custom_lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function_process_data_eqtl import *\n",
    "from function_asso import *\n",
    "from function_mesa_cca import *\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Kinship Matrix for Later Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 56s, sys: 5min 6s, total: 7min 2s\n",
      "Wall time: 6min 40s\n"
     ]
    }
   ],
   "source": [
    "predata_dir = os.path.join(\"..\", \"prepro_data\", \"kinship\")\n",
    "freeze8_kinship_filename = \"freeze8_kinship.feather\"\n",
    "freeze8_kinship_dir_filename = os.path.join(predata_dir, freeze8_kinship_filename)\n",
    "%time freeze8_kinship_df = pd.read_feather(freeze8_kinship_dir_filename, use_threads = True)\n",
    "freeze8_sample_list = list(freeze8_kinship_df)\n",
    "freeze8_sample_df = pd.DataFrame(data=freeze8_sample_list, columns=[\"NWDID\"])\n",
    "freeze8_kinship_df_ID = pd.concat(objs=[freeze8_sample_df, freeze8_kinship_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load rs2302524, rs2633317, rs4251805, rs4760, rs73935023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_ver = \"freeze8\"\n",
    "snp_dir = os.path.join(\"..\", \"raw_data\", \"snp\")\n",
    "save_dir = os.path.join(\"..\", \"prepro_data\", \"snp\")\n",
    "snp_id_dict = {\"rs2302524\":\"whole\", \"rs2633317\":\"whole\", \"rs4251805\":\"whole\", \"rs4760\":\"whole\", \"rs73935023\":\"whole\"}\n",
    "snp_col_list = [6, 6, 6, 6, 6]\n",
    "snp_dir_filename_list = [os.path.join(snp_dir, \"%s_%s.raw\"%(snp_ver, snp_id)) for snp_id in snp_id_dict]\n",
    "snp_df_list = save_snp_dict_each(snp_dir_filename_list, snp_id_dict, snp_ver, save_dir, snp_col_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load rs334, rs399145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/proj/yunligrp/users/minzhi/custom_lib/function_process_data_eqtl.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  snp_df.dropna(axis = 0, how = \"any\", inplace = True)\n"
     ]
    }
   ],
   "source": [
    "snp_ver = \"freeze8\"\n",
    "snp_dir = os.path.join(\"..\", \"raw_data\", \"snp\")\n",
    "save_dir = os.path.join(\"..\", \"prepro_data\", \"snp\")\n",
    "snp_id_dict = {\"rs334\":\"hetero\", \"rs399145\":\"whole\", \"rs11248850\":\"whole\"}\n",
    "snp_col_list = [6, 6, 6]\n",
    "snp_dir_filename_list = [os.path.join(snp_dir, \"%s_%s.raw\"%(snp_ver, snp_id)) for snp_id in snp_id_dict]\n",
    "snp_df_list = save_snp_dict_each(snp_dir_filename_list, snp_id_dict, snp_ver, save_dir, snp_col_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eGFR and APOL1 Status x Gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding CKD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_dir = os.path.join(\"..\", \"prepro_data\", \"phenotype\")\n",
    "pheno_filename = \"freeze8_anno05_af02_unique02_egfr.tsv\"\n",
    "pheno_dir_filename = os.path.join(pheno_dir, pheno_filename)\n",
    "pheno = pd.read_csv(pheno_dir_filename, sep = \"\\t\", header = 0, index_col = None)\n",
    "pheno_ckd = one_condition_conversion(pheno, \"EGFRCKDEPI\", 60, \"CKD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_ckd_dir = os.path.join(\"..\", \"prepro_data\", \"phenotype\")\n",
    "pheno_ckd_filename = \"freeze8_anno05_af02_unique02_egfr-ckd.tsv\"\n",
    "pheno_ckd_dir_filename = os.path.join(pheno_ckd_dir, pheno_ckd_filename)\n",
    "pheno_ckd.to_csv(pheno_ckd_dir_filename, sep = \"\\t\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting into Each Cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### egfr-ckd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "egfr_dir = os.path.join(\"..\", \"prepro_data\", \"phenotype\")\n",
    "egfr_filename = \"freeze8_anno05_af02_unique02_egfr-ckd.tsv\"\n",
    "egfr_dir_filename = os.path.join(egfr_dir, egfr_filename)\n",
    "egfr = pd.read_csv(egfr_dir_filename, sep = \"\\t\", header = 0, index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = egfr\n",
    "df = egfr\n",
    "cat_col = \"study\"\n",
    "anno_merge_col_list = [\"NWDID\"]\n",
    "df_merge_col_list = [\"NWDID\"]\n",
    "all_cohorts = True\n",
    "save_filename_prefix = \"freeze8_anno05_af02_unique02_egfr-ckd\"\n",
    "save_dir_root = os.path.join(\"..\", \"apol1\")\n",
    "save_dir_base = \"pre_data\"\n",
    "cohort_list = df_splitter(anno, df, cat_col, anno_merge_col_list, df_merge_col_list,\n",
    "                          all_cohorts, save_filename_prefix, save_dir_root, save_dir_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To \"all_cohorts\", same dataframe, but different size and loaded as two different dataframes (df1.equals(df2) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_dir_filename = \"/proj/yunligrp/users/minzhi/asso/apol1/all_cohorts/pre_data/freeze8_anno05_af02_unique02_egfr-ckd.tsv\"\n",
    "df2_dir_filename = \"/proj/yunligrp/users/minzhi/asso/apol1/all_cohorts/pre_data/freeze8_anno05_af02_unique02_egfr-ckd_all_cohorts.tsv\"\n",
    "df1 = pd.read_csv(df1_dir_filename, sep = \"\\t\", header = 0, index_col = None)\n",
    "df2 = pd.read_csv(df2_dir_filename, sep = \"\\t\", header = 0, index_col = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### APOL1 Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "apol1_dir = os.path.join(\"..\", \"prepro_data\", \"apol1\")\n",
    "apol1_filename = \"APOL1_status.tsv\"\n",
    "apol1_dir_filename = os.path.join(apol1_dir, apol1_filename)\n",
    "apol1 = pd.read_csv(apol1_dir_filename, sep = \"\\t\", header = 0, index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_dir = os.path.join(\"..\", \"prepro_data\", \"phenotype\")\n",
    "anno_filename = \"freeze8_anno05_af02_unique02_egfr-ckd.tsv\"\n",
    "anno_dir_filename = os.path.join(anno_dir, anno_filename)\n",
    "anno = pd.read_csv(anno_dir_filename, sep = \"\\t\", header = 0, index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apol1\n",
    "cat_col = \"study\"\n",
    "anno_merge_col_list = [\"NWDID\"]\n",
    "df_merge_col_list = [\"NWDID\"]\n",
    "all_cohorts = True\n",
    "save_filename_prefix = \"apol1\"\n",
    "save_dir_root = os.path.join(\"..\", \"apol1\")\n",
    "save_dir_base = \"pre_data\"\n",
    "cohort_list = df_splitter(anno, df, cat_col, anno_merge_col_list, df_merge_col_list,\n",
    "                          all_cohorts, save_filename_prefix, save_dir_root, save_dir_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Cohorts togeother vs. Multiple SNPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23885, 23886)\n",
      "all_cohorts common samples found.\n",
      "(23885, 23886)\n",
      "all_cohorts common samples found.\n",
      "(23885, 23886)\n",
      "all_cohorts common samples found.\n",
      "(23885, 23886)\n",
      "all_cohorts common samples found.\n",
      "(23885, 23886)\n",
      "all_cohorts common samples found.\n"
     ]
    }
   ],
   "source": [
    "status_name = \"apol1\"\n",
    "cohort_list = [\"all_cohorts\"]\n",
    "freeze_ver = \"freeze8\"\n",
    "pc_num = 11\n",
    "common_col = \"NWDID\"\n",
    "snp_id_dict_list = [{\"rs2302524\":\"whole\"}, {\"rs2633317\":\"whole\"}, {\"rs4251805\":\"whole\"}, {\"rs4760\":\"whole\"}, {\"rs73935023\":\"whole\"}]\n",
    "pheno_prefix = \"freeze8_anno05_af02_unique02_egfr-ckd\"\n",
    "\n",
    "for cohort in cohort_list:\n",
    "    pheno_filename = \"%s_%s.tsv\"%(pheno_prefix, cohort)\n",
    "    status_filename = \"%s_%s.tsv\"%(status_name, cohort)\n",
    "    for snp_id_dict in snp_id_dict_list:\n",
    "        snp_list = list(snp_id_dict.keys())\n",
    "        snp_id_string = \"_\".join(snp_list)\n",
    "        save_dir = os.path.join(\"..\", status_name, cohort, \"ready_data_%s\"%snp_id_string)\n",
    "        snp_filename_list = []\n",
    "        for snp_id in snp_id_dict:\n",
    "            snp_type = snp_id_dict[snp_id]\n",
    "            snp_filename = \"%s_%s_%s.tsv\"%(freeze_ver, snp_id, snp_type)\n",
    "            snp_filename_list.append(snp_filename)\n",
    "        common_gene_status_pc_pheno_kinship(status_name, cohort, freeze_ver, pc_num, common_col, freeze8_kinship_df_ID,\n",
    "                                            snp_filename_list, snp_list, pheno_filename, status_filename, save_dir)\n",
    "        print(\"%s common samples found.\"%cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_univar_interact(cohort, gen_name, status_name, load_dir):\n",
    "    save_dir = load_dir\n",
    "    status_filename = \"common_%s.tsv\"%status_name\n",
    "    status_dir_filename = os.path.join(load_dir, status_filename)\n",
    "    status = pd.read_csv(status_dir_filename, sep=\"\\t\", header = 0, index_col = None)\n",
    "    \n",
    "    gen_filename = \"common_%s.tsv\"%gen_name\n",
    "    gen_dir_filename = os.path.join(load_dir, gen_filename)\n",
    "    gen = pd.read_csv(gen_dir_filename, sep = \"\\t\", header = 0, index_col = None)\n",
    "    \n",
    "    status_gen = genxgen(status, gen, status_name, gen_name, common_col, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs2302524 completed.\n",
      "rs2633317 completed.\n",
      "rs4251805 completed.\n",
      "rs4760 completed.\n",
      "rs73935023 completed.\n",
      "all_cohorts completed.\n"
     ]
    }
   ],
   "source": [
    "status_name = \"apol1\"\n",
    "cohort_list = [\"all_cohorts\"]\n",
    "common_col = \"NWDID\"\n",
    "snp_id_dict_list = [{\"rs2302524\":\"whole\"}, {\"rs2633317\":\"whole\"}, {\"rs4251805\":\"whole\"}, {\"rs4760\":\"whole\"}, {\"rs73935023\":\"whole\"}]\n",
    "\n",
    "phenotype_list = [\"EGFRCKDEPI\", \"CKD\"]\n",
    "table_dict_list = [{\"rs2302524\":[\"rs2302524\", \"apol1-rs2302524\"]}, {\"rs2633317\":[\"rs2633317\", \"apol1-rs2633317\"]},\n",
    "                   {\"rs4251805\":[\"rs4251805\", \"apol1-rs4251805\"]}, {\"rs4760\":[\"rs4760\", \"apol1-rs4760\"]},\n",
    "                   {\"rs73935023\":[\"rs73935023\", \"apol1-rs73935023\"]}]\n",
    "adad_dict = {\"quan\":[], \"cati\":[\"AA\", \"ethnicity\", \"study\"]}\n",
    "\n",
    "for cohort in cohort_list:\n",
    "    for table_dict, snp_id_dict in zip(table_dict_list, snp_id_dict_list):\n",
    "        snp_id_list = list(snp_id_dict.keys())\n",
    "        snp_id_string = \"_\".join(snp_id_list)\n",
    "        \n",
    "        load_dir = os.path.join(\"..\", status_name, cohort, \"ready_data_%s\"%snp_id_string)\n",
    "        gen_name = snp_id_string\n",
    "        table_univar_interact(cohort, gen_name, status_name, load_dir)\n",
    "        wrap_prepare_matrix_pheno_adad_in_pheno(status_name, phenotype_list, table_dict, load_dir, adad_dict)\n",
    "    print(\"%s completed.\"%cohort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each Cohorts vs. rs334 and rs399145"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 376)\n",
      "DHS common samples found.\n",
      "(1612, 1613)\n",
      "WHI common samples found.\n",
      "(709, 710)\n",
      "CHS common samples found.\n",
      "(1682, 1683)\n",
      "ARIC common samples found.\n",
      "(3132, 3133)\n",
      "JHS common samples found.\n",
      "(1090, 1091)\n",
      "MESA common samples found.\n",
      "(7708, 7709)\n",
      "HCHS_SOL common samples found.\n",
      "(205, 206)\n",
      "GeneSTAR common samples found.\n",
      "(1844, 1845)\n",
      "HyperGEN common samples found.\n",
      "(1091, 1092)\n",
      "GENOA common samples found.\n",
      "(3413, 3414)\n",
      "FHS common samples found.\n",
      "(1014, 1015)\n",
      "CARDIA common samples found.\n"
     ]
    }
   ],
   "source": [
    "egfr_dir = os.path.join(\"..\", \"prepro_data\", \"phenotype\")\n",
    "egfr_filename = \"freeze8_anno05_af02_unique02_egfr-ckd.tsv\"\n",
    "egfr_dir_filename = os.path.join(egfr_dir, egfr_filename)\n",
    "egfr = pd.read_csv(egfr_dir_filename, sep = \"\\t\", header = 0, index_col = None)\n",
    "_, cohort_list = categorize_df(egfr, \"study\")\n",
    "\n",
    "status_name = \"apol1\"\n",
    "freeze_ver = \"freeze8\"\n",
    "pc_num = 11\n",
    "common_col = \"NWDID\"\n",
    "snp_id_dict_list = [{\"rs334\":\"hetero\", \"rs399145\":\"whole\", \"rs11248850\":\"whole\"}]\n",
    "pheno_prefix = \"freeze8_anno05_af02_unique02_egfr-ckd\"\n",
    "\n",
    "for cohort in cohort_list:\n",
    "    pheno_filename = \"%s_%s.tsv\"%(pheno_prefix, cohort)\n",
    "    status_filename = \"%s_%s.tsv\"%(status_name, cohort)\n",
    "    for snp_id_dict in snp_id_dict_list:\n",
    "        snp_list = list(snp_id_dict.keys())\n",
    "        snp_id_string = \"_\".join(snp_list)\n",
    "        save_dir = os.path.join(\"..\", status_name, cohort, \"ready_data_%s\"%snp_id_string)\n",
    "        snp_filename_list = []\n",
    "        for snp_id in snp_id_dict:\n",
    "            snp_type = snp_id_dict[snp_id]\n",
    "            snp_filename = \"%s_%s_%s.tsv\"%(freeze_ver, snp_id, snp_type)\n",
    "            snp_filename_list.append(snp_filename)\n",
    "        common_gene_status_pc_pheno_kinship(status_name, cohort, freeze_ver, pc_num, common_col, freeze8_kinship_df_ID,\n",
    "                                            snp_filename_list, snp_list, pheno_filename, status_filename, save_dir)\n",
    "        print(\"%s common samples found.\"%cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_apol1(cohort, gen_name_list, status_name, common_col, load_dir):\n",
    "    save_dir = load_dir\n",
    "    status_filename = \"common_%s.tsv\"%status_name\n",
    "    status_dir_filename = os.path.join(load_dir, status_filename)\n",
    "    status = pd.read_csv(status_dir_filename, sep=\"\\t\", header = 0, index_col = None)\n",
    "    \n",
    "    gen_list = []\n",
    "    for gen_name in gen_name_list:\n",
    "        gen_filename = \"common_%s.tsv\"%gen_name\n",
    "        gen_dir_filename = os.path.join(load_dir, gen_filename)\n",
    "        gen = pd.read_csv(gen_dir_filename, sep = \"\\t\", header = 0, index_col = None)\n",
    "        genxgen(status, gen, status_name, gen_name, common_col, save_dir)\n",
    "        gen_list.append(gen)\n",
    "        \n",
    "    genxgen(gen_list[0], gen_list[1], gen_name_list[0], gen_name_list[1], common_col, save_dir)\n",
    "    genxgen(gen_list[0], gen_list[2], gen_name_list[0], gen_name_list[2], common_col, save_dir)\n",
    "    genxgen(gen_list[1], gen_list[2], gen_name_list[1], gen_name_list[2], common_col, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_apol1 completed.\n",
      "GeneSTAR completed.\n",
      "table_apol1 completed.\n",
      "GENOA completed.\n",
      "table_apol1 completed.\n",
      "HyperGEN completed.\n",
      "table_apol1 completed.\n",
      "WHI completed.\n",
      "table_apol1 completed.\n",
      "ARIC completed.\n",
      "table_apol1 completed.\n",
      "CARDIA completed.\n",
      "table_apol1 completed.\n",
      "JHS completed.\n",
      "table_apol1 completed.\n",
      "CHS completed.\n",
      "table_apol1 completed.\n",
      "HCHS_SOL completed.\n",
      "table_apol1 completed.\n",
      "FHS completed.\n",
      "table_apol1 completed.\n",
      "MESA completed.\n",
      "table_apol1 completed.\n",
      "DHS completed.\n"
     ]
    }
   ],
   "source": [
    "egfr_dir = os.path.join(\"..\", \"prepro_data\", \"phenotype\")\n",
    "egfr_filename = \"freeze8_anno05_af02_unique02_egfr-ckd.tsv\"\n",
    "egfr_dir_filename = os.path.join(egfr_dir, egfr_filename)\n",
    "egfr = pd.read_csv(egfr_dir_filename, sep = \"\\t\", header = 0, index_col = None)\n",
    "_, cohort_list = categorize_df(egfr, \"study\")\n",
    "\n",
    "status_name = \"apol1\"\n",
    "common_col = \"NWDID\"\n",
    "snp_id_dict_list = [{\"rs334\":\"hetero\", \"rs399145\":\"whole\", \"rs11248850\":\"whole\"}]\n",
    "\n",
    "phenotype_list = [\"EGFRCKDEPI\", \"CKD\"]\n",
    "table_dict_list = [{\"table_apol1\":[\"rs334\", \"rs399145\", \"rs11248850\", \"apol1-rs334\", \"apol1-rs399145\", \"apol1-rs11248850\",\n",
    "                                   \"rs334-rs399145\", \"rs334-rs11248850\", \"rs399145-rs11248850\"]}]\n",
    "adad_dict = {\"quan\":[], \"cati\":[\"AA\", \"ethnicity\"]}\n",
    "\n",
    "for cohort in cohort_list:\n",
    "    for table_dict, snp_id_dict in zip(table_dict_list, snp_id_dict_list):\n",
    "        snp_id_list = list(snp_id_dict.keys())\n",
    "        snp_id_string = \"_\".join(snp_id_list)\n",
    "        \n",
    "        load_dir = os.path.join(\"..\", status_name, cohort, \"ready_data_%s\"%snp_id_string)\n",
    "        gen_name = snp_id_string\n",
    "        table_apol1(cohort, snp_id_list, status_name, common_col, load_dir)\n",
    "        wrap_prepare_matrix_pheno_adad_in_pheno(status_name, phenotype_list, table_dict, load_dir, adad_dict)\n",
    "    print(\"%s completed.\"%cohort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Each Type of APOL1 Status, rs334, rs399145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = \"APOL1\"\n",
    "load_dir = os.path.join(\"..\", \"cohort\", cohort, \"ready_data\")\n",
    "apol1_filename = \"common_status.tsv\"\n",
    "apol1_dir_filename = os.path.join(load_dir, apol1_filename)\n",
    "apol1 = pd.read_csv(apol1_dir_filename, sep=\"\\t\")\n",
    "\n",
    "rs334_filename = \"common_rs334.tsv\"\n",
    "rs334_dir_filename = os.path.join(load_dir, rs334_filename)\n",
    "rs334 = pd.read_csv(rs334_dir_filename, sep=\"\\t\")\n",
    "\n",
    "rs399145_filename = \"common_rs399145.tsv\"\n",
    "rs399145_dir_filename = os.path.join(load_dir, rs399145_filename)\n",
    "rs399145 = pd.read_csv(rs399145_dir_filename, sep=\"\\t\")\n",
    "\n",
    "egfr_filename = \"common_pheno_adad_dummy.tsv\"\n",
    "egfr_dir_filename = os.path.join(load_dir, egfr_filename)\n",
    "egfr = pd.read_csv(egfr_dir_filename, sep = \"\\t\", header = 0, index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {\"APOL1\":apol1, \"rs334\":rs334, \"rs399145\":rs399145}\n",
    "common_col = \"NWDID\"\n",
    "save_dir = os.path.join(\"..\", \"data_summary\")\n",
    "value_tuple = (egfr, \"EGFRCKDEPI\")\n",
    "df_name_list = [\"APOL1\", \"rs334\", \"rs399145\"]\n",
    "for case_col_list in list(combinations(df_name_list,2)):\n",
    "    df_list = [df_dict[case_col_list[0]], df_dict[case_col_list[1]]]\n",
    "    overlap_num_df, overlap_value_df = overlap_num_all_cases(df_list, case_col_list, common_col, save_dir, value_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
